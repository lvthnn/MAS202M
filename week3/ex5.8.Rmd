---
title: "Exercise 5.8"
author: "KÃ¡ri Hlynsson"
date: "2024-01-21"
output: html_document
---

We will now perform cross-validation on a simulated data set.

## Part (a)

Generate a simulated data set as follows:

``` r
set.seed(1)
x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)
```

In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form.

```{r}
set.seed(1)
x <- rnorm(100)
e <- rnorm(100)
y <- x - 2 * x^2 + e
```

The model we have generated has $n = 100$ and $p = 2$ and

$$
X_i \sim \mathcal N(0, 1) \quad \text{and} \quad Y_i = X_i - 2X_i^2 \quad \forall i \in \{1, \ldots, 100\}
$$

## Part (b)

Create a scatter plot of $X$ against $Y$. Comment on what you find.

```{r}
plot(x, y, xlab = "X", ylab = "Y")
```

Parabola shape.

## Part (c)

Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:

1.  $Y = \beta_0 + \beta_1 X + \epsilon$

2.  $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \epsilon$

3.  $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \epsilon$

4.  $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \beta_4 X^4 + \epsilon$

Note that you may find it helpful to use the `data.frame()` function to create a single data set containing both $X$ and $Y$.

```{r}
library(boot)
df <- data.frame(x, y)

cv.res <- sapply(1:4, function(d) {
  glm.fit <- glm(y ~ poly(x, d, raw = TRUE), data = df)
  loocv <- cv.glm(df, glm.fit)$delta

  names(loocv) <- c("raw", "biased")
  return(list(loocv, glm.fit))
})

cv_errs <- do.call(cbind, cv.res[1,])
colnames(cv_errs) <- paste0("model", 1:4)

models <- cv.res[2,]
```

The cross validation errors are virtually identical for each model, so there does not seem to be any induced bias in the LOOCV process.

```{r}
plot(1:4, cv_errs[1,], type = "b", xlab = "Polynomial degree", ylab = "LOOCV error")
```

```{r}
which.min(cv_errs[1,])
```

Upon including the quadratic term most of the variance in the data is explained. In fact, the cubic and quartic terms fail to reach statistical significance.

```{r}
do.call(anova, c(models, test = "F"))
```

It helps to display the models visually against the data to get a feel for how the fit changes with an increase in polynomial degree.

```{r}
plot(df$x, df$y, xlab = "X", ylab = "Y")
catch <- sapply(1:4, function(d) {
  poly.mdl  <- models[[d]]
  poly.pred <- predict(poly.mdl, df)
  ord <- order(x)
  
  lines(x[ord], poly.pred[ord], col = d + 1, lwd = 2.5, lty = d)
})

legend("bottom", inset = c(0.05, 0.05), legend = paste("Model", 1:4), horiz = TRUE,
       lwd = 2.5, col = 2:5, lty = 1:4, cex = 0.8, bty = "n")
```

## Part (d)

Repeat (c) using another random seed, and report your results. Are your results the same as what you got in (c)? Why?

When the code below is run it shows very little different in the results, only in the visualisation do we see a difference which stems solely from the fact that a different random vector underlies the data and thus the range will vary accordingly.

```{r}
set.seed(42)
x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)

df <- data.frame(x, y)

cv.res <- sapply(1:4, function(d) {
  glm.fit <- glm(y ~ poly(x, d, raw = TRUE), data = df)
  loocv <- cv.glm(df, glm.fit)$delta

  names(loocv) <- c("raw", "biased")
  return(list(loocv, glm.fit))
})

cv_errs <- do.call(cbind, cv.res[1,])
colnames(cv_errs) <- paste0("model", 1:4)

models <- cv.res[2,]

plot(df$x, df$y, xlab = "X", ylab = "Y")
catch <- sapply(1:4, function(d) {
  poly.mdl  <- models[[d]]
  poly.pred <- predict(poly.mdl, df)
  ord <- order(x)
  
  lines(x[ord], poly.pred[ord], col = d + 1, lwd = 2.5, lty = d)
})

legend("bottom", inset = c(0.05, 0.05), legend = paste("Model", 1:4), horiz = TRUE,
       lwd = 2.5, col = 2:5, lty = 1:4, cex = 0.8, bty = "n")
```

## Part (e)

Which of the models in (c) had the smallest LOOCV error? Is that what you expected? Explain your answer.

Model 2, I have explained this.

## Part (f)

Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?

Yes, I have explained this above.
